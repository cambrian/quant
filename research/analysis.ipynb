{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy scipy pandas matplotlib numpy_ringbuffer sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "\n",
    "currencies = ['usd', 'btc', 'eth', 'ltc', 'xrp', 'eos']\n",
    "pairs = [c + '_usd' for c in currencies if c != 'usd']\n",
    "volume_keys = [c + '_tx_volume' for c in currencies if c != 'usd']\n",
    "\n",
    "def prep_data(file):\n",
    "    data = pickle.load(open(file, 'rb'))\n",
    "    dates = [x['date'] for x in data]\n",
    "    prices = [{k:v for k,v in x.items() if k in pairs} for x in data]\n",
    "    volumes = [{(k.partition('_')[0] + '_usd'):v for k,v in x.items() if k in volume_keys} for x in data]\n",
    "    return {\n",
    "        'prices': pd.DataFrame(prices, index = dates),\n",
    "        'volumes': pd.DataFrame(volumes, index = dates)\n",
    "    }\n",
    "\n",
    "def reduce_data(data, resampling):\n",
    "    '''Averages prices, sums volumes'''\n",
    "    prices = data['prices'].resample(resampling).first().fillna(method='ffill')\n",
    "    volumes = data['volumes'].resample(resampling).sum().fillna(method='ffill')\n",
    "    return { 'prices': prices, 'volumes': volumes }\n",
    "\n",
    "def tail_data(data, n):\n",
    "    '''get the last n points of the given data'''\n",
    "    prices = data['prices'].tail(n)\n",
    "    volumes = data['volumes'].tail(n)\n",
    "    return { 'prices': prices, 'volumes': volumes }\n",
    "\n",
    "def viz_data(data):\n",
    "    '''Only plots prices for now'''\n",
    "    plt.plot(data['prices'] / data['prices'].mean() - 1)\n",
    "    plt.show()\n",
    "\n",
    "def find_gaps(data, freq):\n",
    "    idx_ref = pd.date_range(start=data.index[0], end=data.index[-1],freq=freq)\n",
    "    gaps = idx_ref[~idx_ref.isin(data.index)]\n",
    "    return gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prep_data('data/data.p')\n",
    "data_min = reduce_data(prep_data('data/data-minute.p'), '1Min')\n",
    "data_5min = reduce_data(data_min, '5Min')\n",
    "data_15min = reduce_data(data_min, '15Min')\n",
    "viz_data(data_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix(df,size=10):\n",
    "    '''Function plots a graphical correlation matrix for each pair of columns in the dataframe.\n",
    "\n",
    "    Input:\n",
    "        df: pandas DataFrame\n",
    "        size: vertical and horizontal size of the plot'''\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(size, size))\n",
    "    ax.matshow(df)\n",
    "    plt.xticks(range(len(df.columns)), df.columns);\n",
    "    plt.yticks(range(len(df.index)), df.index);\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(len(df.index)):\n",
    "        for j in range(len(df.columns)):\n",
    "            ax.text(j, i, '{:0.2f}'.format(df.iloc[i, j]), ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "plot_matrix(data_15min['prices'].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_correlate_(x, y):\n",
    "    return np.argmax(np.correlate(x, y, mode='full')) - len(x) + 1\n",
    "\n",
    "def cross_correlate(df):\n",
    "    '''Compute cross-correlation matrix for the given dataframe.'''\n",
    "    ccs = pd.DataFrame(index=df.columns, columns=df.columns)\n",
    "    for i in df.columns:\n",
    "        for j in df.columns:\n",
    "            if i == j:\n",
    "                ccs.loc[i,j] = 0\n",
    "                continue\n",
    "            if np.isnan(ccs.loc[i,j]):\n",
    "                ccs.loc[i,j] = cross_correlate_(df[i], df[j])\n",
    "                ccs.loc[j,i] = -ccs.loc[i,j]\n",
    "    return ccs\n",
    "\n",
    "print(cross_correlate(pd.DataFrame([[1,2],[2,1],[1,2],[2,1],[1,2]])))\n",
    "print(cross_correlate(pd.DataFrame([[1,1],[2,2],[3,3],[4,4],[5,5]])))\n",
    "    \n",
    "print(cross_correlate(data_min['prices']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from trader.util.stats import Gaussian\n",
    "\n",
    "# Note: Assumes all orders fill at last trade price. Attempting to simulate market-making would\n",
    "# require combing through book and trade data, which is too much work for us to do at the moment.\n",
    "\n",
    "\n",
    "def data_currencies(data):\n",
    "    currencies = ['usd']\n",
    "    for pair in data['prices'].columns:\n",
    "        currencies.append(pair.partition('_')[0])\n",
    "    return currencies\n",
    "\n",
    "def get_orders(balances, prices, fairs, size, fees):\n",
    "    '''Given current balances, prices, and fair estimates, determine which orders to place.\n",
    "    Assumes all pairs are XXX_USD.\n",
    "    `fairs` should be a Gaussian type. '''\n",
    "    edges = (fairs / prices) - 1\n",
    "    def subtract_fees_toward_zero(x):\n",
    "        if abs(x) < fees:\n",
    "            return 0\n",
    "        if x > 0:\n",
    "            return x - fees\n",
    "        return x + fees\n",
    "    edges = Gaussian(edges.mean.apply(subtract_fees_toward_zero), edges.covariance)\n",
    "#     edges = (prices - fairs.mean) / fairs.stddev  # edges relative to the fair price\n",
    "    balances = balances.drop(['usd']).rename(lambda c: c + '_usd')\n",
    "    target_balance_values = edges.mean / edges.stddev * size\n",
    "\n",
    "    proposed_orders = (target_balance_values / prices - balances)\n",
    "#     edge_better_than_fees = np.abs(fairs.mean / prices - 1) > fees\n",
    "    # only buy cheap and sell expensive even if it means we overshoot our target balance\n",
    "    good_direction = edges.mean * proposed_orders < 0\n",
    "\n",
    "    return proposed_orders * good_direction\n",
    "\n",
    "\n",
    "def execute_orders(fees, prices, balances, orders):\n",
    "    for (pair, size) in orders.items():\n",
    "        currency = pair.partition(\"_\")[0]\n",
    "        value = size * prices[pair]\n",
    "        balances['usd'] -= value\n",
    "        balances['usd'] -= abs(value) * fees\n",
    "        balances[currency] += size\n",
    "\n",
    "\n",
    "def run(strategy, data, size=1000, fees=0):\n",
    "    balances = pd.Series(dict.fromkeys(data_currencies(data), 0.))\n",
    "    balances_ = []\n",
    "    fairs_ = []\n",
    "    index = data['prices'].index\n",
    "    for (date, prices) in data['prices'].iterrows():\n",
    "        volumes = data['volumes'].loc[date]\n",
    "\n",
    "        fairs = strategy.step(prices, volumes)\n",
    "        orders = get_orders(balances, prices, fairs, size, fees)\n",
    "        execute_orders(fees, prices, balances, orders)\n",
    "\n",
    "        fairs_.append(fairs)\n",
    "        balances_.append(balances.copy())\n",
    "    return {\n",
    "        'data': data,\n",
    "        'fairs': pd.DataFrame(fairs_, index=index),\n",
    "        'balances': pd.DataFrame(balances_, index=index)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strategy import HoldStrategy\n",
    "from execution import analyze\n",
    "\n",
    "analyze(run(HoldStrategy(), data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strategy import KalmanFilterStrategy\n",
    "\n",
    "analyze(run(KalmanFilterStrategy(correlation_window_size = 64, movement_half_life = 3), data_15min, fees=0.002))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strategy import Strategy\n",
    "from trader.util.stats import Ema, Gaussian\n",
    "from execution import analyze\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy_ringbuffer import RingBuffer\n",
    "\n",
    "\n",
    "class KalmanFilter(Strategy):\n",
    "    '''Predicts fairs based on correlated movements between pairs.\n",
    "    All inputs should be cointegrated.'''\n",
    "\n",
    "    def __init__(self, correlation_window_size, movement_half_life):\n",
    "        self.moving_prices_history = None\n",
    "        self.correlation_window_size = correlation_window_size\n",
    "        self.moving_prices = Ema(movement_half_life)\n",
    "        self.moving_volumes = Ema(correlation_window_size)\n",
    "        self.prev_prediction = None\n",
    "\n",
    "    def step(self, prices, volumes):\n",
    "        if self.moving_prices_history is None:\n",
    "            self.moving_prices_history = RingBuffer(\n",
    "                self.correlation_window_size, dtype=(np.float, len(prices.index)))\n",
    "\n",
    "        if self.prev_prediction is None:\n",
    "            self.prev_prediction = self.null_estimate(prices)\n",
    "\n",
    "        self.moving_prices.step(prices)\n",
    "        self.moving_volumes.step(volumes)\n",
    "\n",
    "        if not self.moving_prices.ready:\n",
    "            return self.null_estimate(prices)\n",
    "\n",
    "        self.moving_prices_history.append(self.moving_prices.value)\n",
    "\n",
    "        if len(self.moving_prices_history) < self.correlation_window_size:\n",
    "            return self.null_estimate(prices)\n",
    "\n",
    "        df = pd.DataFrame(np.array(self.moving_prices_history), columns=prices.index)\n",
    "        diffs = df.diff().iloc[1:]\n",
    "        diff = Gaussian(diffs.iloc[-1], diffs.var())\n",
    "        # Could also calculate diff from the raw price movements but using smoothed movements\n",
    "        # for diff seems to improve RoR\n",
    "\n",
    "        \n",
    "        stddevs = df.std()\n",
    "        corr = df.corr()\n",
    "        deltas = prices - df.mean()\n",
    "        predicted_delta_means = corr.mul(deltas, axis=0).mul(stddevs, axis=1).div(stddevs, axis=0)\n",
    "        volume_signals = np.sqrt(self.moving_volumes.value * self.prev_prediction.mean)\n",
    "        volume_factor = np.max(volume_signals) / volume_signals\n",
    "        predicted_delta_variances = np.abs(df.cov().mul(stddevs, axis=1).div(stddevs, axis=0)) * volume_factor / (corr * corr)\n",
    "        predicted_deltas = Gaussian.intersect([Gaussian(\n",
    "            predicted_delta_means.loc[i], predicted_delta_variances.loc[i]) for i in prices.index])\n",
    "\n",
    "        print(predicted_deltas)\n",
    "        print(diff)\n",
    "        print(df.mean())\n",
    "        print(predicted_deltas + df.mean())\n",
    "        print(Gaussian.sum([self.prev_prediction, diff]))\n",
    "        new_prediction = Gaussian.sum([self.prev_prediction, diff]) & (predicted_deltas + df.mean())\n",
    "        self.prev_prediction = new_prediction\n",
    "        return new_prediction\n",
    "\n",
    "analyze(run(KalmanFilter(correlation_window_size = 64, movement_half_life = 1), data_15min, fees=0.002))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strategy import CointegratorStrategy\n",
    "\n",
    "analyze(run(CointegratorStrategy(cointegration_window_size = 64), tail_data(data, 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(run(CointegratorStrategy(cointegration_window_size = 16), data_15min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(run(KalmanFilterStrategy(\n",
    "    correlation_window_size = 480,\n",
    "    movement_half_life = 1\n",
    "), tail_data(data_min, 10000), fees = 0.002))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strategy import CombinedStrategy\n",
    "\n",
    "analyze(run(CombinedStrategy([\n",
    "    KalmanFilterStrategy(correlation_window_size = 60, movement_half_life = 3),\n",
    "    CointegratorStrategy(cointegration_window_size = 16)\n",
    "]), data_15min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(run(CointegratorStrategy(cointegration_window_size = 512), data_5min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(run(KalmanFilterStrategy(correlation_window_size = 165, movement_half_life = 70), data_5min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(run(CombinedStrategy([\n",
    "    KalmanFilterStrategy(correlation_window_size = 16, movement_half_life = 8),\n",
    "    CointegratorStrategy(cointegration_window_size = 64)\n",
    "]), tail_data(data_min, 1500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def find_best_window_sizes(data, n):\n",
    "    points = []\n",
    "    best = None\n",
    "    best_ror = 0\n",
    "    for _ in range(n):\n",
    "        movement_half_life = random.expovariate(1) * 15\n",
    "#         window_ratio = random.uniform(1, 10)\n",
    "#         window_size = max(3, int(movement_half_life * window_ratio))\n",
    "#         movement_half_life = 2\n",
    "        window_size = int(random.expovariate(1) * 100) + 400\n",
    "#         window_size = int(random.expovariate(1) * 30) + 3\n",
    "#         window_size = 4\n",
    "#         window_size = 32\n",
    "        print('Trying window_size: {0} and half_life: {1}'.format(window_size, movement_half_life))\n",
    "        ror = analyze(run(KalmanFilterStrategy(window_size, movement_half_life), data, fees = 0.002), plot=False)\n",
    "        print('  RoR: {0}'.format(ror))\n",
    "        point = { 'window_size': window_size, 'half_life': movement_half_life, 'RoR': ror }\n",
    "        points.append(point)\n",
    "        if ror > best_ror:\n",
    "            best = point\n",
    "            best_ror = ror\n",
    "    print('Best found:')\n",
    "    print(best)\n",
    "    pd.DataFrame(points).plot.scatter('window_size', 'half_life', c='RoR', colormap='jet')\n",
    "    \n",
    "find_best_window_sizes(tail_data(data_min, 1500), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
