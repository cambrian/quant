{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy scipy pandas matplotlib numpy_ringbuffer sklearn\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currencies = ['usd', 'btc', 'eth', 'ltc', 'xrp', 'eos']\n",
    "# pairs = [c + '_usd' for c in currencies if c != 'usd']\n",
    "# volume_keys = [c + '_tx_volume' for c in currencies if c != 'usd']\n",
    "\n",
    "# def prep_data(file):\n",
    "#     data = pickle.load(open(file, 'rb'))\n",
    "#     dates = [x['date'] for x in data]\n",
    "#     prices = [{k:v for k,v in x.items() if k in pairs} for x in data]\n",
    "#     volumes = [{(k.partition('_')[0] + '_usd'):v for k,v in x.items() if k in volume_keys} for x in data]\n",
    "#     return {\n",
    "#         'prices': pd.DataFrame(prices, index = dates),\n",
    "#         'volumes': pd.DataFrame(volumes, index = dates)\n",
    "#     }\n",
    "\n",
    "# def reduce_data(data, resampling):\n",
    "#     '''Averages prices, sums volumes'''\n",
    "#     prices = data['prices'].resample(resampling).first().fillna(method='ffill')\n",
    "#     volumes = data['volumes'].resample(resampling).sum().fillna(method='ffill')\n",
    "#     return { 'prices': prices, 'volumes': volumes }\n",
    "\n",
    "# def tail_data(data, n):\n",
    "#     '''get the last n points of the given data'''\n",
    "#     prices = data['prices'].tail(n)\n",
    "#     volumes = data['volumes'].tail(n)\n",
    "#     return { 'prices': prices, 'volumes': volumes }\n",
    "\n",
    "# def viz_data(data):\n",
    "#     '''Only plots prices for now'''\n",
    "#     plt.plot(data['prices'] / data['prices'].mean() - 1)\n",
    "#     plt.show()\n",
    "\n",
    "# def find_gaps(data, freq):\n",
    "#     idx_ref = pd.date_range(start=data.index[0], end=data.index[-1],freq=freq)\n",
    "#     gaps = idx_ref[~idx_ref.isin(data.index)]\n",
    "#     return gaps\n",
    "\n",
    "# data = prep_data('data/data.p')\n",
    "# data_min = reduce_data(prep_data('data/data-minute.p'), '1Min')\n",
    "# data_5min = reduce_data(data_min, '5Min')\n",
    "# data_15min = reduce_data(data_min, '15Min')\n",
    "# viz_data(data_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min = pd.read_hdf('data/1min.h5')\n",
    "data_15min = data_min.resample('15Min').first()\n",
    "data_1h = data_min.resample('1h').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_data = data_15min.apply(lambda x: x['price'])\n",
    "(price_data / price_data.mean()).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_matrix(df,size=10):\n",
    "#     '''Function plots a graphical correlation matrix for each pair of columns in the dataframe.\n",
    "\n",
    "#     Input:\n",
    "#         df: pandas DataFrame\n",
    "#         size: vertical and horizontal size of the plot'''\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(size, size))\n",
    "#     ax.matshow(df)\n",
    "#     plt.xticks(range(len(df.columns)), df.columns);\n",
    "#     plt.yticks(range(len(df.index)), df.index);\n",
    "#     # Loop over data dimensions and create text annotations.\n",
    "#     for i in range(len(df.index)):\n",
    "#         for j in range(len(df.columns)):\n",
    "#             ax.text(j, i, '{:0.2f}'.format(df.iloc[i, j]), ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "# plot_matrix(data_15min['prices'].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_correlate_(x, y):\n",
    "#     return np.argmax(np.correlate(x, y, mode='full')) - len(x) + 1\n",
    "\n",
    "# def cross_correlate(df):\n",
    "#     '''Compute cross-correlation matrix for the given dataframe.'''\n",
    "#     ccs = pd.DataFrame(index=df.columns, columns=df.columns)\n",
    "#     for i in df.columns:\n",
    "#         for j in df.columns:\n",
    "#             if i == j:\n",
    "#                 ccs.loc[i,j] = 0\n",
    "#                 continue\n",
    "#             if np.isnan(ccs.loc[i,j]):\n",
    "#                 ccs.loc[i,j] = cross_correlate_(df[i], df[j])\n",
    "#                 ccs.loc[j,i] = -ccs.loc[i,j]\n",
    "#     return ccs\n",
    "\n",
    "# print(cross_correlate(pd.DataFrame([[1,2],[2,1],[1,2],[2,1],[1,2]])))\n",
    "# print(cross_correlate(pd.DataFrame([[1,1],[2,2],[3,3],[4,4],[5,5]])))\n",
    "    \n",
    "# print(cross_correlate(data_min['prices']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### import numpy as np\n",
    "import pandas as pd\n",
    "from trader.util.stats import Gaussian\n",
    "\n",
    "# Note: Assumes all orders fill at last trade price. Attempting to simulate market-making would\n",
    "# require combing through book and trade data, which is too much work for us to do at the moment.\n",
    "\n",
    "def data_currencies(data):\n",
    "    quote_currency = data.iloc[0].index[0].partition(\"_\")[2]\n",
    "    currencies = [quote_currency]\n",
    "    for pair in data.iloc[0].index:\n",
    "        currencies.append(pair.partition('_')[0])\n",
    "    return currencies\n",
    "\n",
    "def get_orders(balances, prices, fairs, size, fees, min_edge):\n",
    "    '''Given current balances, prices, and fair estimates, determine which orders to place.\n",
    "    Assumes all pairs are XXX_USD.\n",
    "    `fairs` should be a Gaussian type. '''\n",
    "    quote_currency = prices.index[0].partition(\"_\")[2]\n",
    "    \n",
    "    gradient = fairs.gradient(prices) * fairs.mean\n",
    "    balance_direction_vector = gradient / (np.linalg.norm(gradient) + 1e-100)\n",
    "    target_balance_values = balance_direction_vector * fairs.z_score(prices) * size\n",
    "    pair_balances = balances.drop([quote_currency]).rename(lambda c: '{}_{}'.format(c, quote_currency))\n",
    "    proposed_orders = target_balance_values / prices - pair_balances\n",
    "    profitable = np.sign(proposed_orders) * (fairs.mean / prices - 1) > fees + min_edge\n",
    "    profitable_orders = proposed_orders * profitable\n",
    "    \n",
    "#     unprofitable_balance = pair_balances * edge.mean < 0\n",
    "#     # TODO: in the near future we should model this via the cdf of the profitable order cutoff\n",
    "#     p_reversion = 0.6\n",
    "#     profitability_gross_edge_cutoff = fees + edge.stddev * min_edge\n",
    "#     positive_ev_from_closing_position = p_reversion * (gross_edge.mean - fees) > (1-p_reversion) * (profitability_gross_edge_cutoff - fees)\n",
    "#     balance_closing_orders = -pair_balances * unprofitable_balance * positive_ev_from_closing_position\n",
    "\n",
    "    return profitable_orders # + balance_closing_orders\n",
    "\n",
    "\n",
    "def execute_orders(fees, prices, balances, orders):\n",
    "    for (pair, size) in orders.items():\n",
    "        currency, quote_currency = pair.split(\"_\")\n",
    "        value = size * prices[pair]\n",
    "        balances[quote_currency] -= value\n",
    "        balances[quote_currency] -= abs(value) * fees\n",
    "        balances[currency] += size\n",
    "\n",
    "\n",
    "def run(strategy, data, size=1000, fees=0, min_edge = 0):\n",
    "    balances = pd.Series(dict.fromkeys(data_currencies(data), 0.))\n",
    "    balances_ = []\n",
    "    fairs_ = []\n",
    "    for frame in data:\n",
    "        fairs = strategy.step(frame)\n",
    "        orders = get_orders(balances, frame['price'], fairs, size, fees, min_edge)\n",
    "        execute_orders(fees, frame['price'], balances, orders)\n",
    "\n",
    "        fairs_.append(fairs)\n",
    "        balances_.append(balances.copy())\n",
    "    return {\n",
    "        'data': data,\n",
    "        'fairs': pd.DataFrame(fairs_, index=data.index),\n",
    "        'balances': pd.DataFrame(balances_, index=data.index)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strategy import HoldStrategy\n",
    "from execution import analyze\n",
    "\n",
    "analyze(run(HoldStrategy(), data_min.tail(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strategy import KalmanFilterStrategy\n",
    "\n",
    "analyze(run(KalmanFilterStrategy(correlation_window_size = 64, movement_half_life = 3), data_15min, fees=0.002))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strategy import Strategy\n",
    "from trader.util.stats import Ema, Gaussian\n",
    "from execution import analyze\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy_ringbuffer import RingBuffer\n",
    "from statsmodels.tsa.stattools import coint\n",
    "\n",
    "def coint(df):\n",
    "    ratios = pd.DataFrame(0, index=df.columns, columns=df.columns)\n",
    "    p_values = pd.DataFrame(0, index=df.columns, columns=df.columns)\n",
    "    for i in df.columns:\n",
    "        for j in df.columns:\n",
    "            if ratios.loc[i,j] == 0 and i != j:\n",
    "                out.loc[i,j] = coint(df[i], df[j])\n",
    "                out.loc[j,i] = out.loc[j,i]\n",
    "\n",
    "\n",
    "class KalmanFilter(Strategy):\n",
    "    '''Predicts fairs based on correlated movements between pairs.\n",
    "    All inputs should be cointegrated.'''\n",
    "\n",
    "    def __init__(self, correlation_window_size, movement_half_life):\n",
    "        self.moving_prices_history = None\n",
    "        self.correlation_window_size = correlation_window_size\n",
    "        self.moving_prices = Ema(movement_half_life)\n",
    "        self.moving_volumes = Ema(correlation_window_size / 2)\n",
    "        self.prev_prediction = None\n",
    "\n",
    "    def step(self, frame):\n",
    "        prices = frame['price']\n",
    "        volumes = frame['volume']\n",
    "        if self.moving_prices_history is None:\n",
    "            self.moving_prices_history = RingBuffer(\n",
    "                self.correlation_window_size, dtype=(np.float64, len(prices.index)))\n",
    "\n",
    "        if self.prev_prediction is None:\n",
    "            self.prev_prediction = self.null_estimate(prices)\n",
    "\n",
    "        self.moving_prices.step(prices)\n",
    "        self.moving_volumes.step(volumes)\n",
    "\n",
    "        if not self.moving_prices.ready:\n",
    "            return self.null_estimate(prices)\n",
    "\n",
    "        self.moving_prices_history.append(self.moving_prices.value)\n",
    "\n",
    "        if len(self.moving_prices_history) < self.correlation_window_size:\n",
    "            return self.null_estimate(prices)\n",
    "\n",
    "        df = pd.DataFrame(self.moving_prices_history, columns=prices.index)\n",
    "        diffs = df.diff().iloc[1:]\n",
    "        diff = Gaussian(diffs.iloc[-1], diffs.cov())\n",
    "        # Could also calculate diff from the raw price movements but using smoothed movements\n",
    "        # for diff seems to improve RoR\n",
    "\n",
    "        \n",
    "        stddevs = df.std()\n",
    "        corr = df.corr()\n",
    "#         r2 = corr * corr\n",
    "#         cov = df.cov()\n",
    "        deltas = prices - df.mean()\n",
    "#         volume_signals = np.sqrt(self.moving_volumes.value * self.prev_prediction.mean)\n",
    "#         volume_factor = np.max(volume_signals) / volume_signals\n",
    "#         correlated_predictions = []\n",
    "#         for pair, delta in deltas.items():\n",
    "#             correlated_mean = corr[pair] * stddevs * delta / stddevs[pair]\n",
    "#             correlated_covariance = cov.div(r2[pair], axis=1) * volume_factor[pair]# * np.abs(delta) / stddevs[pair]\n",
    "#             correlated_predictions.append(Gaussian(correlated_mean, correlated_covariance))\n",
    "#         predicted_deltas = Gaussian.intersect(correlated_predictions)\n",
    "#         print(predicted_deltas)\n",
    "        predicted_delta_means = corr.mul(deltas, axis=0).mul(stddevs, axis=1).div(stddevs, axis=0)\n",
    "        predicted_delta_variances = np.abs(df.cov().mul(stddevs, axis=1).div(stddevs, axis=0)) / (corr * corr + 1e-100)\n",
    "        predicted_deltas = Gaussian.intersect([Gaussian(\n",
    "            predicted_delta_means.loc[i], predicted_delta_variances.loc[i]) for i in prices.index])\n",
    "        new_prediction = (self.prev_prediction + diff) & (predicted_deltas + df.mean())\n",
    "        self.prev_prediction = new_prediction\n",
    "        return new_prediction\n",
    "\n",
    "analyze(run(KalmanFilter(correlation_window_size = 64, movement_half_life = 1), data_15min.tail(2000), fees=0.00075, min_edge=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strategy import CointegratorStrategy\n",
    "\n",
    "analyze(run(CointegratorStrategy(cointegration_window_size = 128), data_15min.tail(1500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy_ringbuffer import RingBuffer\n",
    "import pickle\n",
    "\n",
    "from research.strategy.base import Strategy\n",
    "from trader.util.stats import Ema, Gaussian\n",
    "from trader.util.linalg import orthogonal_projection\n",
    "\n",
    "class Cointegrator(Strategy):\n",
    "    def __init__(self, coint_file):\n",
    "        coint = pickle.load(open(coint_file, 'rb'))\n",
    "        self.A = coint['cointegrated_vectors']\n",
    "        self.historical_mean_prices = coint['mean_prices']\n",
    "        self.covs = coint['residual_covariances']\n",
    "        self.prev_prices = None\n",
    "        \n",
    "    def __cointegrated_fairs(self, prices, base_prices):\n",
    "        prices_norm = prices / base_prices - 1\n",
    "        fair_means = [prices - orthogonal_projection(prices_norm, x) * base_prices for x in self.A.values]\n",
    "        fairs = [Gaussian(mean, self.covs[i] * len(fair_means)) for i, mean in enumerate(fair_means)]\n",
    "        return Gaussian.intersect(fairs)\n",
    "\n",
    "    def step(self, frame):\n",
    "        # TODO check that frame contains the currencies that the model was trained on\n",
    "        prices = frame[\"price\"]\n",
    "#         assert np.array_equal(\n",
    "#             prices.index,\n",
    "#             np.array([\"BTC_USDT\", \"XRP_USDT\", \"ETH_USDT\", \"LTC_USDT\", \"NEO_USDT\", \"EOS_USDT\"]),\n",
    "#         )\n",
    "        \n",
    "        if self.prev_prices is None:\n",
    "            self.prev_prices = prices\n",
    "            return self.null_estimate(prices)\n",
    "            \n",
    "        step_fairs = self.__cointegrated_fairs(prices, self.prev_prices)\n",
    "        fairs = self.__cointegrated_fairs(prices, self.historical_mean_prices)\n",
    "        prediction = fairs & step_fairs\n",
    "        \n",
    "        return prediction\n",
    "\n",
    "analyze(run(Cointegrator(\"coint.p\"), data_15min.tail(2000), fees=0.002, min_edge=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy_ringbuffer import RingBuffer\n",
    "import pickle\n",
    "\n",
    "from research.strategy.base import Strategy\n",
    "from trader.util.stats import Ema, Gaussian\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "from trader.util.linalg import orthogonal_projection, hyperplane_projection\n",
    "\n",
    "class LiveCointegrator(Strategy):\n",
    "    def __init__(self, window_size, cointegration_frequency=4):\n",
    "        self.window_size = window_size\n",
    "        self.cointegration_period = window_size // cointegration_frequency\n",
    "        self.sample_counter = 0\n",
    "        self.price_history = None\n",
    "        self.A = None\n",
    "        self.base_prices = None\n",
    "        self.covs = None\n",
    "        self.prev_prediction = None\n",
    "\n",
    "    def step(self, frame):\n",
    "        prices = frame[\"price\"]\n",
    "        \n",
    "        if self.price_history is None:\n",
    "            self.price_history = RingBuffer(self.window_size, dtype=(np.float64, len(prices.index)))\n",
    "            \n",
    "        if self.prev_prediction is None:\n",
    "            self.prev_prediction = self.null_estimate(prices)\n",
    "            \n",
    "        self.price_history.append(prices)\n",
    "        \n",
    "        if len(self.price_history) < self.window_size:\n",
    "            return self.null_estimate(prices)\n",
    "        \n",
    "        if self.sample_counter == 0:\n",
    "            P = pd.DataFrame(self.price_history, columns=prices.index)\n",
    "            self.base_prices = P.mean()\n",
    "            P_norm = P / self.base_prices - 1\n",
    "\n",
    "            c = coint_johansen(P_norm, det_order=-1, k_ar_diff=1)\n",
    "            \n",
    "#             tail = P.tail(self.cointegration_period)\n",
    "#             c_tail = coint_johansen(tail - tail.mean(), det_order=-1, k_ar_diff=1)\n",
    "#             tail_cointegrated = np.any((c_tail.lr1 > c_tail.cvt[:,1]) * (c_tail.lr2 < c_tail.cvm[:,2]))\n",
    "\n",
    "            significant_results = (c.lr1 > c.cvt[:,1]) * (c.lr2 < c.cvm[:,2])\n",
    "            if np.any(significant_results): # and tail_cointegrated:\n",
    "                self.A = pd.DataFrame(c.evec[:, significant_results].T, columns=prices.index)\n",
    "                covs = []\n",
    "                for a in self.A.values:\n",
    "                    prediction_cov = orthogonal_projection(P_norm, a).cov()\n",
    "                    w_pred, v_pred = np.linalg.eigh(prediction_cov)\n",
    "                    w_sam, v_sam = np.linalg.eigh(P_norm.cov())\n",
    "#                     print(w_pred)\n",
    "#                     print(v_pred)\n",
    "#                     print(w_sam)\n",
    "#                     print(v_sam)\n",
    "                    w_reg = w_pred + w_sam\n",
    "                    regularized_cov = v_pred @ np.diag(w_reg) @ v_pred.T\n",
    "#                     u_pred, s_pred, vh_pred = np.linalg.svd(prediction_cov)\n",
    "#                     u_sam, s_sam, vh_sam = np.linalg.svd(P_norm.cov())\n",
    "#                     s_reg = s_pred + s_sam\n",
    "# #                     print(s_pred)\n",
    "# #                     print(s_sam)\n",
    "# #                     print(prediction_cov)\n",
    "# #                     print(u_pred @ np.diag(s_pred) @ vh_pred)\n",
    "#                     regularized_cov = u_pred @ np.diag(s_reg) @ vh_pred\n",
    "#                     regularized_cov = pd.DataFrame(regularized_cov, index=P.columns, columns=P.columns)\n",
    "# #                     print(regularized_cov)\n",
    "                    covs.append(regularized_cov)\n",
    "                self.covs = covs\n",
    "            else:\n",
    "                self.A = None\n",
    "                self.covs = None\n",
    "            \n",
    "        self.sample_counter -= 1\n",
    "        self.sample_counter %= self.cointegration_period\n",
    "        \n",
    "        if self.A is None:\n",
    "            return self.null_estimate(prices)\n",
    "        \n",
    "        prices_norm = prices / self.base_prices - 1\n",
    "        fair_means = [(hyperplane_projection(prices_norm, a) + 1) * self.base_prices for a in self.A.values]\n",
    "        prediction = Gaussian(fair_means[0], self.covs[0])\n",
    "#         fairs = [Gaussian(mean, self.covs[i]) for i, mean in enumerate(fair_means)]\n",
    "#         prediction = Gaussian.intersect(fairs)\n",
    "        return prediction\n",
    "\n",
    "analyze(run(LiveCointegrator(window_size=128), data_15min.tail(2000), fees=0.001, min_edge=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy_ringbuffer import RingBuffer\n",
    "import pickle\n",
    "\n",
    "from research.strategy.base import Strategy\n",
    "from trader.util.stats import Ema, Gaussian\n",
    "from trader.util.linalg import orthogonal_projection, hyperplane_projection\n",
    "from statsmodels.tsa.stattools import coint\n",
    "\n",
    "def plot_gaussian(x, y, gaussian):\n",
    "    z = gaussian.pdf(np.dstack(np.meshgrid(x,y)))\n",
    "    plt.pcolormesh(x, y, z)\n",
    "    plt.show()\n",
    "\n",
    "class LivePairCointegrator(Strategy):\n",
    "    def __init__(self, window_size, cointegration_frequency=4):\n",
    "        self.window_size = window_size\n",
    "        self.cointegration_period = window_size // cointegration_frequency\n",
    "        self.sample_counter = 0\n",
    "        self.price_history = None\n",
    "\n",
    "    def step(self, frame):\n",
    "        prices = frame[\"price\"]\n",
    "        \n",
    "        if self.price_history is None:\n",
    "            self.price_history = RingBuffer(self.window_size, dtype=(np.float64, len(prices.index)))\n",
    "            \n",
    "        self.price_history.append(prices)\n",
    "        \n",
    "        if len(self.price_history) < self.window_size:\n",
    "            return self.null_estimate(prices)\n",
    "        \n",
    "        df = pd.DataFrame(self.price_history, columns=prices.index)\n",
    "        mean = df.mean()\n",
    "        deltas = df / mean - 1\n",
    "        stddev = deltas.std() + 1e-10\n",
    "        regression_slope = deltas.corr().mul(stddev, axis=1).div(stddev, axis=0)\n",
    "        delta = deltas.iloc[-1]\n",
    "        \n",
    "        if self.sample_counter == 0:\n",
    "            coint_p = pd.DataFrame(0, index=prices.index, columns=prices.index)\n",
    "            prediction_covs = {}\n",
    "            for pair_i in prices.index:\n",
    "                for pair_j in prices.index:\n",
    "                    if pair_i >= pair_j:\n",
    "                        continue\n",
    "                    p = coint(df[pair_i], df[pair_j])[1]\n",
    "                    coint_p.loc[pair_i, pair_j] = p\n",
    "                    coint_p.loc[pair_j, pair_i] = p\n",
    "                    deltas_ij = deltas[[pair_i, pair_j]]\n",
    "                    regression_vector = [regression_slope.loc[pair_i][pair_j], -1]\n",
    "                    prediction_cov = orthogonal_projection(deltas_ij, regression_vector).cov()\n",
    "                    prediction_eigenvalues, prediction_eigenvectors = np.linalg.eig(prediction_cov)\n",
    "                    sample_eigenvalues, sample_eigenvectors = np.linalg.eig(deltas_ij.cov())\n",
    "                    regularized_eigenvalues = prediction_eigenvalues + sample_eigenvalues\n",
    "                    regularized_cov = prediction_eigenvectors @ np.diag(regularized_eigenvalues) @ prediction_eigenvectors.T\n",
    "                    regularized_cov = pd.DataFrame(regularized_cov, index=deltas_ij.columns, columns=deltas_ij.columns)\n",
    "#                     prediction = Gaussian(pd.Series(0, index=deltas_ij.columns), prediction_cov)\n",
    "#                     base = Gaussian(pd.Series(0, index=deltas_ij.columns), deltas_ij.cov())\n",
    "#                     regularized = Gaussian(pd.Series(0, index=deltas_ij.columns), regularized_cov)\n",
    "#                     prediction_cov = deltas_ij.cov()\n",
    "                    prediction_covs[pair_i, pair_j] = regularized_cov\n",
    "                    prediction_covs[pair_j, pair_i] = regularized_cov[::-1].T[::-1]\n",
    "#                     xrange = deltas[pair_i].max() - deltas[pair_i].min()\n",
    "#                     yrange = deltas[pair_j].max() - deltas[pair_j].min()\n",
    "#                     x = np.linspace(-xrange, xrange)\n",
    "#                     y = np.linspace(-yrange, yrange)\n",
    "#                     print(prediction_cov)\n",
    "#                     print(deltas_ij.cov())\n",
    "#                     print(regularized_cov)\n",
    "#                     plot_gaussian(x, y, prediction)\n",
    "#                     plot_gaussian(x, y, base)\n",
    "#                     plot_gaussian(x, y, regularized)\n",
    "#                     print('abs')\n",
    "#                     df[[pair_i, pair_j]].plot.scatter(x=pair_i,y=pair_j)\n",
    "#                     plt.show()\n",
    "                    \n",
    "            self.coint_f = (coint_p * coint_p * 900).clip(1) # discount predictions for p values > .03\n",
    "            self.prediction_covs = prediction_covs\n",
    "            \n",
    "        self.sample_counter -= 1\n",
    "        self.sample_counter %= self.cointegration_period\n",
    "        \n",
    "        fairs = []\n",
    "        base_cov = df.cov()\n",
    "#         print('')\n",
    "        for pair_i in prices.index:\n",
    "            for pair_j in prices.index:\n",
    "                if pair_i >= pair_j:\n",
    "                    continue\n",
    "                regression_vector = [regression_slope.loc[pair_i][pair_j], -1]\n",
    "#                 residuals = orthogonal_projection(deltas[[pair_i, pair_j]], regression_vector)\n",
    "                fair_delta_mean = hyperplane_projection(delta[[pair_i, pair_j]], regression_vector)\n",
    "                fair_cov = self.prediction_covs[pair_i, pair_j] * self.coint_f.loc[pair_i, pair_j]\n",
    "                fair = Gaussian(fair_delta_mean, fair_cov)\n",
    "#                 print(fair)\n",
    "#                 x = np.linspace(deltas[pair_i].min(), deltas[pair_i].max()) - deltas[pair_i].mean()\n",
    "#                 y = np.linspace(deltas[pair_j].min(), deltas[pair_j].max()) - deltas[pair_j].mean()\n",
    "#                 plot_gaussian(x, y, fair)\n",
    "#                 plot_gaussian(x, y, Gaussian(pd.Series(0, index=[pair_i, pair_j]), residuals.cov()))\n",
    "#                 plot_gaussian(x, y, Gaussian(pd.Series(0, index=[pair_i, pair_j]), deltas[[pair_i, pair_j]].cov()))\n",
    "                fairs.append(fair)\n",
    "        fair = (Gaussian.intersect(fairs) + 1) * mean\n",
    "#         print(fair)\n",
    "#         print(base_cov)\n",
    "#         x = np.linspace(df['BTC_USDT'].min(), df['BTC_USDT'].max())\n",
    "#         y = np.linspace(df['ETH_USDT'].min(), df['ETH_USDT'].max())\n",
    "#         print(prices)\n",
    "#         print(fair)\n",
    "#         print(fair[['BTC_USDT', 'ETH_USDT']])\n",
    "#         plot_gaussian(x, y, fair[['BTC_USDT', 'ETH_USDT']])\n",
    "#         print(fair - prices)\n",
    "        return fair\n",
    "\n",
    "analyze(run(LivePairCointegrator(window_size=128), data_15min.tail(500), fees=0.001, min_edge=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(run(CointegratorStrategy(cointegration_window_size = 16), data_15min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(run(KalmanFilterStrategy(\n",
    "    correlation_window_size = 480,\n",
    "    movement_half_life = 1\n",
    "), tail_data(data_min, 10000), fees = 0.002))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strategy import CombinedStrategy\n",
    "\n",
    "analyze(run(CombinedStrategy([\n",
    "    KalmanFilterStrategy(correlation_window_size = 60, movement_half_life = 3),\n",
    "    CointegratorStrategy(cointegration_window_size = 16)\n",
    "]), data_15min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(run(CointegratorStrategy(cointegration_window_size = 512), data_5min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(run(KalmanFilterStrategy(correlation_window_size = 165, movement_half_life = 70), data_5min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze(run(CombinedStrategy([\n",
    "    KalmanFilterStrategy(correlation_window_size = 16, movement_half_life = 8),\n",
    "    CointegratorStrategy(cointegration_window_size = 64)\n",
    "]), tail_data(data_min, 1500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def find_best_window_sizes(data, n):\n",
    "    points = []\n",
    "    best = None\n",
    "    best_ror = 0\n",
    "    for _ in range(n):\n",
    "        movement_half_life = random.expovariate(1) * 15\n",
    "#         window_ratio = random.uniform(1, 10)\n",
    "#         window_size = max(3, int(movement_half_life * window_ratio))\n",
    "#         movement_half_life = 2\n",
    "        window_size = int(random.expovariate(1) * 100) + 400\n",
    "#         window_size = int(random.expovariate(1) * 30) + 3\n",
    "#         window_size = 4\n",
    "#         window_size = 32\n",
    "        print('Trying window_size: {0} and half_life: {1}'.format(window_size, movement_half_life))\n",
    "        ror = analyze(run(KalmanFilter(window_size, movement_half_life), data, fees = 0.002), plot=False)\n",
    "        print('  RoR: {0}'.format(ror))\n",
    "        point = { 'window_size': window_size, 'half_life': movement_half_life, 'RoR': ror }\n",
    "        points.append(point)\n",
    "        if ror > best_ror:\n",
    "            best = point\n",
    "            best_ror = ror\n",
    "    print('Best found:')\n",
    "    print(best)\n",
    "    pd.DataFrame(points).plot.scatter('window_size', 'half_life', c='RoR', colormap='jet')\n",
    "    \n",
    "find_best_window_sizes(tail_data(data_min, 1500), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
